name: Update Latest Substack Articles

on:
  schedule:
    - cron: '0 */6 * * *' # Runs every 6 hours
  workflow_dispatch: # Allows manual triggering
  push:
    branches: [ main ]
    paths:
      - '.github/workflows/update-substack.yml'

jobs:
  update-readme:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          token: ${{ secrets.GITHUB_TOKEN }}

      - name: Fetch latest 5 Substack posts
        run: |
          RSS_URL="https://peterlimg.substack.com/feed"
          
          echo "Attempting to fetch RSS feed from $RSS_URL"
          
          # Try to fetch RSS feed with proper headers
          if curl -L -A "Mozilla/5.0 (compatible; GitHubActions/1.0)" \
               -H "Accept: application/rss+xml, application/xml, text/xml" \
               --connect-timeout 30 \
               --max-time 60 \
               --retry 3 \
               --retry-delay 5 \
               "$RSS_URL" -o rss_feed.xml; then
            
            echo "RSS feed fetched successfully"
            
            # Parse RSS with Python for more reliable parsing
            echo "Extracting articles from RSS feed..."
            
            # Create Python script file
            cat > parse_rss.py << 'EOF'
import xml.etree.ElementTree as ET

try:
    tree = ET.parse('rss_feed.xml')
    root = tree.getroot()
    items = root.findall('.//item')[:5]
    
    articles = []
    for item in items:
        title_elem = item.find('title')
        link_elem = item.find('link')
        
        if title_elem is not None and link_elem is not None:
            title = title_elem.text
            link = link_elem.text
            
            if title and title.startswith('<![CDATA[') and title.endswith(']]>'):
                title = title[9:-3]
            
            if title and link:
                articles.append(f"- [{title}]({link}) - *Recent*")
    
    if articles:
        with open('articles.txt', 'w') as f:
            for article in articles:
                f.write(article + '\n')
        print(f"Successfully extracted {len(articles)} articles")
        for article in articles:
            print(article)
    else:
        print("No articles found in RSS feed")
        
except Exception as e:
    print(f"Error parsing RSS: {e}")
EOF

            # Run the Python script
            python3 parse_rss.py
            
            if [ -f articles.txt ] && [ -s articles.txt ]; then
              echo "RSS parsing successful"
              echo "=== Articles found ==="
              cat articles.txt
              echo "=== End articles ==="
            else
              echo "RSS parsing failed, using fallback"
              rm -f articles.txt
            fi
          else
            echo "Failed to fetch RSS feed, using fallback"
          fi
          
          # Fallback to hardcoded articles if RSS failed
          if [ ! -f articles.txt ] || [ ! -s articles.txt ]; then
            echo "Creating fallback articles.txt"
            cat > articles.txt << 'EOF'
- [Building Better Cloud Cost Testing: The Fox Tool Story](https://peterlimg.substack.com/p/building-better-cloud-cost-testing) - *June 2025*
- [How I Built an AI-Powered AWS Cost Optimization Engine](https://peterlimg.substack.com/p/how-i-built-an-ai-powered-aws-cost) - *June 2025*
- [Move Fast with Mathematical Certainty: How I Rebuilt My FinOps Platform in 48 Hours](https://peterlimg.substack.com/p/move-fast-with-mathematical-certainty) - *June 2025*
- [The Architecture Migration That Nobody Sees](https://peterlimg.substack.com/p/the-architecture-migration-that-nobody) - *June 2025*
- [From Prototype to Product: Adding Multi-Tenant Architecture](https://peterlimg.substack.com/p/from-prototype-to-product-adding) - *June 2025*
EOF
          fi
          
          echo "=== Final articles.txt content ==="
          cat articles.txt
          echo "=== End final content ==="

      - name: Update README
        run: |
          # Debug: Check if articles.txt was created and has content
          echo "=== Debug: articles.txt content ==="
          ls -la articles.txt || echo "articles.txt not found"
          cat articles.txt || echo "articles.txt is empty"
          echo "=== End Debug ==="
          
          # Use a simpler approach with sed and temp files
          # Split README into before, articles, and after sections
          
          # Get content before the START marker
          sed '/<!-- SUBSTACK:START -->/,$d' README.md > before.tmp
          
          # Get content after the END marker  
          sed -n '/<!-- SUBSTACK:END -->/,$p' README.md > after.tmp
          
          # Combine: before + start marker + articles + end marker + after
          cat before.tmp > README.tmp
          echo "<!-- SUBSTACK:START -->" >> README.tmp
          cat articles.txt >> README.tmp
          cat after.tmp >> README.tmp
          
          # Debug: Show differences
          echo "=== Debug: README diff ==="
          diff README.md README.tmp || echo "Files differ (this is expected)"
          echo "=== End Debug ==="
          
          # Replace original README
          mv README.tmp README.md
          
          # Cleanup
          rm -f before.tmp after.tmp

      - name: Commit and Push changes
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "Update latest Substack articles in README"
          file_pattern: README.md